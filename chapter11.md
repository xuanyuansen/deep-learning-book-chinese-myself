###第十一章方法论
成功使用深度学习技术不仅仅需要熟知存在哪些算法和这些算法背后的工作原理，一个优秀的机器学习实践者也需要了解如何选择适合特定应用的算法，以及如何监督和响应来自实验的反馈，来提升机器学习系统的表现。在机器学习系统的日常开发中，从业者需要决定是否要收集更多数据，增加或减少模型的规模，添加或删除正则化特性，提高模型的优化，提升模型的近似推理，或者调试模型的编程实现。尝试所有这些操作都至少是费时的，所以能够决定正确的行动是非常重要的，而不是盲目猜测。本书的大部分内容是关于不同机器学习模型，训练算法和目标函数。这可能给人一种错觉，成为机器学习专家最重要的因素是了解很多机器学习技术，并精通数学。然而在实践中，通常使用一个正确的普通算法远比草率地使用一些晦涩的算法效果好得多。正确使用算法需要掌握一些基本的方法论。本章中的许多建议来源于Ng（2015）。我们推荐如下的实用设计过程：
*	1、设定目标，确定使用何种误差度量。这些目标和误差度量应该以解决问题为目标导向。*	2、尽快建立端到端的工作流，包括合适的性能评估指标。*	3、构建极致的系统来确定性能瓶颈。定位性能低于预期的部分，以及是否存在过拟合，欠拟合，或者数据及软件中的缺陷。*	4、重复进行增量迭代，基于系统的结果进行调整，例如收集新的数据，调整超参数，或者改变算法。举一个现实中的示例，我们以谷歌街景视图地址号码转录系统为例。这个应用的目的是将建筑物添加到谷歌地图中。街景车在拍摄建筑物的同时会记录每张照片的相关GPS坐标。卷积网络识别各照片的地址号码，并允许谷歌地图数据库在正确的位置中添加该地址。该商业应用的开发过程为我们提供了如何遵循我们倡导设计方法的示例。现在我们将描述这个过程中的每个步骤。
####11.1性能度量
对于误差度量的使用而言，确定目标是必要的第一步，因为误差度量将引导你的后续行动。你也应该清楚你预期的效果。请记住对于大多数应用而言，零误差是绝对不可能实现的。贝叶斯错误定义了你能取得的最低错误率，即使能够从无限的训练数据中获得数据的真实分布。这是因为输入特征没有包含输出变量的全部信息，也可能是因为系统内部的随机性。这也会受到训练数据量的局限。训练数据受限的原因有很多，当你的目标是打造最好的现实世界中的产品或服务，通常可以收集更多的数据，但必须确定进一步减少误差的价值，并权衡这与收集更多数据的成本。数据收集可能需要时间，金钱，或人类痛苦（例如，如果你的数据采集过程中涉及执行侵入性的医疗测试） 。当你的目标是要回答哪个算法在固定的基准上表现更好的科学问题时，基准规范通常决定了训练集，是不允许你收集更多的数据。如何才能确定性能水平的合理期望？通常，在学术环境中，我们根据此前公布的基准测试结果可以得到一些错误率的估计。在实际环境中，我们清楚怎样的错误率对于一个应用是安全的，具有成本效益的，或对消费者有吸引力的。一旦你确定了现实期望的错误率，实现这个错误率将指导设计决定。除了性能度量的目标值外，另一个重要的考虑是性能度量的选择。几种不同的性能度量可以被用来测量一个包含机器学习应用的有效性，这些性能度量通常不同于用来训练模型的损失函数。如5.1.2所述，通常可以衡量系统的准确率，或者等价的错误率。然而，许多应用需要更高级的性能度量。有时候犯一种错误的代价比另一种更大。例如，垃圾邮件检测系统会犯两种错误，错误地将一个正常邮件归为垃圾，和错误地让垃圾信息出现在收件箱。阻止合法的消息比让可疑消息通过的危害更大。我们不妨来衡量某种形式的总成本，而不是测量垃圾分类的错误率，其中拦截合法邮件的成本比让垃圾邮件通过的成本更高。有时候我们希望训练一个二值分类器来发现低频事件。例如，我们要设计一个稀有疾病的医药测试。假设百万人中只有一人患病。针对检测任务，通过硬编码使分类器总是预报未患疾病，我们能轻松取得99.9999%的准确率。显然准确率对于衡量此类系统的性能不适用。解决该问题的一个方法是使用精度和召回来作为衡量标准。精度是指模型召回数据中正样本的比例，而召回是指召回正确数据占全部正样本的比例。检测器报告没有人患有该疾病可以达到非常高的精度，但是零召回。检测器报告所有人都患有疾病会得到百分之百的召回，但是其精度相当于人群中患此疾病的概率（在此例中是0.0001%，即百万人中仅有1人患病）。当使用精度和召回时，通常可以画出PR曲线，精度是纵轴，召回是横轴。希望被检测到的事件出现时分类器的得分越高。例如，一个前向神经网络预期识别疾病的输出是yˆ = P(y = 1 | x) ，估计一个人患病的概率，其医疗检测结果由特征X描述。当（概率）得分超过某个阈值时我们会报告这个发现。通过调整这个阈值，我们可以权衡精度和召回。在很多情况下，我们希望用一个数字来描述分类器的性能。为此，我们可以将精度P和召回R表示为一个F分数。另一个方法是计算PR曲线下方的面积。
在一些应用中，机器学习系统可以拒绝做出决定。当机器学习算法可以估计出决定的置信度时这是非常有用的，特别是错误的决定会产生危害，或者人工操作可以接管的时候。街景转录系统提供了一个这样的例子。任务是从图片中转换地址数字来将图片的拍摄地址和地图中的地址正确关联。因为地图如果出错的话，地图的价值会严重下降，所以只有地址转换正确时才添加这个地址是非常重要的。如果机器学习系统认为其作出正确转录的可能比人工低时，那么最佳的策略就是允许人工操作员代替系统进行转录。当然，机器学习系统只有在能够大幅减轻人工操作的工作量时才是有用的。在这种情况下性能度量的一个自然选择是覆盖率（coverage），覆盖率是指机器学习系统能做做出响应的样本占全部样本的比例。可以权衡覆盖率和准确率。一个（机器学习系统）总是可以达到100%的准确率如果它拒绝做出任何预测，但是这会使得覆盖率下降到0%。对于街景转录的任务，项目的目标是在维持95%覆盖率的情况下达到人工操作的准确率，而这个准确率是98%。还有许多其他的性能度量。例如我们可以测量点击率，收集用户满意度调查等等。许多特征领域的应用也有该领域内独特的评价方式。重要的是提前决定提高那种性能度量下的表现，然后集中精力到这个性能度量上。如果目标定义不清，就很难确定机器学习系统的性能是否有提升。
####11.2Default Baseline Models 默认基线模型在确定目标和性能度量之后，任何实用系统下一步都要尽快建立一个合理的端到端的系统。在本章节中，我们提供了在各种情况下优先使用哪些算法作为基准线的建议。请记住，深度学习研究进展迅速，所以这篇文章写出后不久，最好的基准算法就有可能变得不可用。根据问题的复杂性，甚至可以不从深度学习算法开始。如果您的问题只需正确选择几个线性的权重就可以解决，也许你可以从简单的统计模型开始，例如逻辑回归。如果清楚地意识到您的问题隶属于“人工智能”的范畴，例如物体识别，语音识别，机器翻译等等，那么从合适的深度学习模型开始会做得很到。首先，基于数据的结构选择模型的一般类别。如果以固定维度的向量为输入进行监督学习，可以使用全连接的前馈神经网络。如果输入包含拓扑结构（例如，输入的是图像），可以使用卷积神经网络。在这种情况下，应该使用分段线性激励函数（ReLUs，或者其一般化形式，例如Leaky ReLus， PreLUs，和Maxout等）。如果输入时序列，使用门限递归网络（例如LSTM或者GRU）。优化算法的一个合理选择就是加入动量的随机梯度下降法，和一个衰减的学习率（处理不同问题时不同的衰减策略表现各异，其中包括线性衰减至一个最小的学习率，指数衰减，或者每当验证错误平稳时衰减2到10分之一）。另一个合理的选择是自适应梯度下降法（Adam）。批量规范化（BN，batch normalization）会对优化的性能产生巨大的影响，特别是卷积神经网络和存在sigmoidal非线性激励的神经网络。开始建立基线就采用“批量规范化”是非常合理的，而如果优化出现问题就更应该尽早引入。除非你的训练集包含千万级以上的数据，否则应该在训练的一开始就加入某种形式的正则化。早期停止（Early Stopping）的策略应该全局使用。Dropout是一个非常好的正则化策略，容易实现而且可以和许多模型和训练算法兼容。“批量规范化”有时也可以降低泛化误差，而且允许省略Dropout，这是因为标准化每个变量时噪声存在于统计估计过程。如果你的任务类似于已经被广泛研究的其他项目，可能首先复制先前在类似任务上表现最好的模型和算法就可以做的很好。甚至可以从先前任务拷贝一个训练好的模型。例如，通常可以使用ImageNet比赛中训练好的卷积神经网络上提取特征来解决其他机器视觉的问题（Girshick et al., 2015）。一个常见的问题是，是否一开始就使用无监督学习，这个问题将在第三部分详细阐述。这个问题在某种程度上是领域相关的。一些领域，例如自然语言处理，是已知的从无监督学习技术中受益很大的，例如学习无监督的词汇向量表示（word embedding）。在其他领域，例如机器视觉，目前非监督学习技术还没有带来太多益处，除了在半监督学习中，当样本中有标签的比例过低时（Kingma et al., 2014; Rasmus et al., 2015）。如果你的应用中无监督学习已经是一个重要的方面，那么将它包含在第一个基线模型中。否则，仅当你要解决的任务是无监督时才在开始的时候尝试无监督学习技术。当你观察到最初的基线模型出现过拟合时你可以随时加入无监督学习。####11.3决定是否要收集更多数据在第一个端到端的系统建立好后，就需要评估算法的性能并决定如何优化。很多机器学习初学者都倾向于尝试许多不同的算法来提升表现。然而，往往收集更多数据效果更好，而不是去优化学习算法本身。怎样才能决定是否要收集更多的数据？首先，确定在训练集上的性能是否可接受。如果在训练集的性能差，学习算法并没有使用已经可用的训练数据，因此没有理由来收集更多的数据。相反，尝试通过添加更多的层或给每层增加更多的隐藏单元来增加模型的大小。此外，尝试通过调整学习速率超参数来改善学习算法，如果更大的模型和精心调校优化的算法不能很好地工作，那么问题可能是训练数据的质量。该数据可能过于嘈杂或者不包括预测期望的输出所需要的正确输入。这意味着需要重新开始收集干净的数据或收集更丰富的特征集。如果在训练集上的性能表现是可接受的，然后评估在测试集上的性能。如果测试集上的表现也是可以接受的，那么就不需要后续操作。如果测试集上的性能比训练集性能糟糕太多，那么收集更多的数据是最有效的解决方案之一。关键因素是采集更多数据的成本和灵活性，和通过其他手段降低验证误差的成本和灵活性，和能够显著提高测试集性能所需的数据量。在拥有用户千万甚至上亿的大型网络公司，收集大型数据集是可行的，而这样做的费用可能比其他方法少很多，所以答案几乎总是收集更多的训练数据。例如，大型标记数据集的​​发展是解决目标识别问题中最重要的因素之一。在其他情况下，如医疗应用中，收集更多的数据可能是昂贵的或不可行的。相比收集更多数据另一个可行的方法是降低模型的尺寸或者增加正则化，通过调整超参数实现，例如权重衰减系数，或者增加正则化策略，例如Dropout。如果您发现即使调整正规化超参数，训练集和测试集之间的性能差距仍然是不能接受的，那么建议收集更多数据。在决定是否要收集更多的数据时，也有必要决定收集多少数据。绘制显示训练集的大小和泛化误差之间关系的曲线是十分有益的，例如图5.4。通过外推这样的曲线，可以预测需要多少额外的训练数据性能才能达到指定水平。一般地，加入样本总数的一小部分将不会对泛化误差产生显著影响。因此建议指数倍数地增加训练样本数量来进行实验，例如倍增训练样本的数量来进行连续实验。如果收集更多的数据是不可行的，改善泛化误差的另一种唯一方法是优化学习算法本身。这是学术研究的领域，而不建议应用实践者参与。####11.4超参数选择大多数深度学习算法都有许多超参数来控制模型诸多方面的表现。这些超参数中一些影响算法的运行时间和内存消耗，另一些影响训练过程中输出模型的质量，和泛化到新的输入时的预测能力。在选择这些超参数时有两种基本方法：手动选择和自动选择。手动选择超参数需要了解超参数到底做了什么以及如何使得机器学习模型获得良好的泛化性能。自动超参数选择算法使得不需要了解超参数背后的原理，但是计算量往往更大。#####11.4.1人工调节超参数要手动设置超参数，必须要了解超参数，训练误差，泛化误差和计算资源（内存使用和运行时间）之间的关系。这意味着有效发挥第五章所介绍学习算法的能力需要在基本原理方面打下坚实的基础。手动超参数搜索的目标通常是在运行时间和内存的限制下找到泛化误差的下限。这里我们不讨论如何确定运行时间和内存对各种超参数的影响，因为这是高度依赖于平台的。手动超参数搜索的主要目的是调整模型的有效能力来胜任任务的复杂性。模型的有效能力受三个方面的因素限制：模型的表达能力，学习算法能够成功地最小化损失函数来训练处模型，以及损失函数和训练过程能够正则化模型到何种程度。模型的层数越多，每层的隐单元数量越多，模型的表达能力越强，即能够表达更复杂的函数。模型并不能保证能够真正学习到所有的函数，如果训练算法不能够发现特征的函数可以很好地降低训练误差，或者正则项会限制其中一些函数，例如权重衰减。将泛化误差作为一个超参数的函数画图，通常会是一个U型曲线，例如图5.3所示。在一个极端情况下，超参数的值对应低表达能力，训练误差高，所以泛化误差也高。这是欠拟合条件下的情况（regime，the conditions under which a scitific or industrial process occurs）。在另一个极端情况下，超参数的值对应高表达能力，泛化误差高，因为训练误差和泛化误差间的差距较大。曲线中间的某个位置对应最优的模型表达能力，在中等训练误差之上增加中等的泛化误差间隔，可以达到尽可能最低的泛化误差。对于一些超参数，当其值过大时会出现过拟合。隐含层的数量就是这样的例子，这是因为增加隐藏层单元的数量会增加模型的表达能力。对于一些超参数，当其值过小时会发生过拟合。例如，权重衰减系数最小为零时，对应学习算法的表达能力是最大的。并不是每个超参数都能够绘制出完整的U型曲线。许多超参数是离散的，例如隐层内的单元数量或者Maxout中线性单元的数量，所以只能访问曲线上的部分点。一些超参数是二进制的。这些超参数通常是一些开关，来指定是否使用算法的某些部分，例如一些通过减去均值并除以标准差进行归一化特征的预处理步骤。这些超参数仅能绘制出曲线上的两个点。另外一些超参数有最大值和最小值的限制而不能绘制曲线的某个部分。例如，最小的权重衰减系数是零。这意味着如果衰减系数为零时模型产生过欠拟合，我们不能通过修改衰减系数进入过拟合区域。换句话说，一些超参数只能降低表达能力。 学习率也许是最重要的超参数。如果仅有调整一个超参数的时间，那么就调整学习率。它比其他超参数更复杂地控制了模型的表达能力，当优化问题的学习率设置正确，即学习率不过大也不过小时，模型的有效表达能力是最大的。训练误差对于学习率可以绘制出U型曲线，例如图11.1所示。当学习率过大时，梯度下降会不经意地增加训练误差而不是降低训练误差。在理想的二次方程情况下，这种情况发生时学习率至少是最优学习率的两倍（LeCun et al., 1998a ）。当学习率太小时，训练过程不仅变得十分缓慢，而且很有可能在训练误差很高时永远卡住。这种效果知之甚少（因为凸优化时永远不会发生）。调整学习率之外的超参数时需要同时注意训练误差和测试误差，来确定模型是过拟合还是欠拟合，然后适当调整模型的表达能力。如果训练集上的误差大于目标错误率，你别无选择只能增加模型的表达能力。如果你选择不使用正则化且确信优化算法能够正确执行，那么必须给网络增加更多的隐层或者隐单元。然而不幸的是，计算开销也随之增加。如果测试集上的误差大于目标错误率，那么可以采取两种办法。测试误差是训练误差与训练与验证误差之间的差距的总和。最优的测试误差是由上述变量之间权衡得到。神经网络通常在训练误差很低时表现良好（即表达能力强时），同时测试误差基本上是由训练误差和测试误差间的间距决定的。你的目标是降低这个间距的速度要超过训练误差增加的速度。为了降低这个间距，需要调整正则化参数来限制模型的有效表达能力，例如增加dropout或者权重衰减。通常情况下，一个正则化较好的大尺寸模型表现最好，如使用dropout。（dropout，maxout这些trick可以深入了解下。）大多数超参数可以通过推理其对模型表达能力的影响来设定。表11.1汇总了一些例子。人工设置超参数时，不要忽视了最终的目标，即在测试集上表现良好。加入正则化是达到目标的唯一方法（防止过拟合）。只要你有足够低的训练误差，总可以通过增加训练数据来降低泛化误差。简单暴力来保证成功的方式是持续增加模型的表达能力和训练数据知道问题解决。这种解决方式确实增加了训练和推理的计算成本，所以只有在资源合适的情况下才是可行的。理论上，这种做法可能会因为优化困难而失败，但是很多问题在模型选择合适的情况下，优化问题并不是一个显著的障碍。#####11.4.2 自动超参数优化算法 Automatic Hyperparameter Optimization Algorithms 理想的学习算法只需要一个数据集就可以输出判别函数，而不需要手动调节超参数。其他学习算法例如逻辑回归（LR）和支持向量机（SVM）流行的部分原因就在于他们能够在只调整一个或两个超参数的情况下表现出色的能力。神经网络有时候调整一小部分超参数就可以表现很好，但往往调节四十多个超参数才能显著受益。当使用者从正确的点入手时，人工调节超参数可以很好地工作，例如由有过类似应用或者架构工作经验的他人来决定，或者使用者本身具有经年累月调整处理类似任务神经网络超参数的经验。然而对于许多应用，这些可以着手的地方并不存在。在这种情况下，自动超参数选择算法能够找到有用的超参数的值。#####11.4.3 Grid Search 网格搜索当仅有3个或更少参数时，常见的做法是采用贪心搜索（grid search）。对于每一个超参数，用户选择一个小的有限集来搜索。网格搜索算法然后对参数笛卡尔乘积中的每个点训练一个模型。然后选择验证误差最小的实验作为寻优得到的最佳超参数。图11.2展示了网格搜索超参数的一个例子。如何确定要搜索值的范围呢？对于数值型（有序）的超参数，应根据类似实验的经验，谨慎选择其最大值和最小值，保证最优值尽可能在这个区间里面。通常，网格搜索需要近似地以指数级来选择变量的值，例如学习率的集合为{0.1，0.01，10-3,10-4,10-5}，隐单元数量的集合{50，100，200，500，1000，2000}。网格搜索通常在执行多次时效果最好。例如，我们对参数A在集合{-1，0，1}上进行网格搜索。如果寻找到的最优值是1，然后发现可能低估了这个区间，我们应该偏移网格再次执行搜索，例如{1，2，3}。如果发现最优值是0，那么我们不妨再放大搜索区间，重新在区间{-0.1，0，0.1}执行网格搜索。网格搜索的明显问题是它的计算量随着超参数的数量呈指数级增长。如果有m个超参数，且每个超参数有n个值，那么训练和验证实验的计算复杂度为O（mn）。实验可以并行的进行，而且是不受限制的并行（不同机器进行搜索时几乎不需要通信）。然而不幸的是，由于网格搜索计算的指数级开销，即使并行计算也可能无法提供满意的搜索计算量。#####11.4.4 Random Search 随机搜索幸运的是，有网格搜索的替代方案，而且易于编程实现，使用方便，且可以快速收敛到较好的超参数，即随机搜索（Bergstra and Bengio, 2012）。随机搜索过程如下。首先我们定义每个超参数边缘分布，例如，二进制或离散超参数的伯努利分布或多项分布（Multinoulli），或者正实值超参数对数的均匀分布。例如，log_learning_rate ∼ u(−1, −5) learning_rate = 10log_learning_rate其中u （A，B ）表示区间（A，B ）上的均匀分布。类似地，log_number_of_hidden_units 可以从区间（log（50），log（2000））采样。和网格搜索不同，不需要离散化话超参数的值。这样可以在不产生额外计算成本的情况下搜索更大的区间。如果11.2所示，当部分超参数对性能影响较小时，随机搜索比网格搜索的效率有指数级提升。Bergstra and Bengio （2012）对这个问题进行了深入研究，就每种方法需要进行的实验次数而言，发现随机搜索比网格搜索可以更迅速地降低验证误差。对于网格搜索，需要经常基于第一次运行的搜索结果进行重复的搜索。随机搜索比网格搜索更快找到最优解的主要原因是，与网格搜索不同（在给定其他超参数的情况下，一个超参数的两个值可能给出相同的结果），而随机搜索却没有白费的实验。在网格搜索的情况下，不同的超参数值可能有相同的运行结果，然而随机搜索情况下，他们通常具有不同的值。因此，如果这两个超参数值的差异并不会明显改变验证集误差，网格搜索会不必要的重复两次等价的实验，而随机搜索仍然会对其他超参数进行两次独立的搜索。
#####11.4.5 Model-Based Hyper-parameter Optimization 基于模型的超参数优化（贝叶斯观点，参数也具有一个分布）超参数的优化搜索可以总结为一个优化问题。决策变量是超参数。要优化的损失函数是使用这些超参数训练得到结果在验证集上的误差。在可以计算验证集误差对于超参数的导数的简化情况下，我们可以简单地按照梯度的方向。然而不幸的是，在大多数实际情况下，这个梯度是不可求的，可能由于其高计算量和内存开销，或者由于超参数与验证集错误具有本质上不可微的相互作用，例如在超参数值是离散的情况下。为了弥补梯度的缺失，我们可以建立验证集误差的模型，然后通过优化这个模型来对超参数做出新的猜测。大多数基于模型的超参数搜索算法使用贝叶斯回归模型去估计验证集误差的期望值和这个期望的不确定性。所以优化涉及exploration（该参数下模型的性能不确定，可能有很大提高也可能表现很差）和exploitation（在该参数下模型的性能可相比于之前任何参数，通常是与之前超参数很类似的参数）之间的权衡。当代超参数优化方法包括Spearmint (Snoek et al., 2012) ，TPE (Bergstra et al., 2011) 和SMAC (Hutter et al., 2011)。
目前我们无法明确地推荐贝叶斯超参数优化方法就是事半功倍地提升深度学习结果的有效工具。有时贝叶斯超参数优化方法可媲美人工专家，有时更好，但有时效果会非常差。确定它是否适用于某个特定的问题可能是值得尝试的，但是并不足够地成熟可靠。话虽这么说，超参数优化仍然是一个重要的研究领域，这主要是由深度学习的需求驱动的，这不仅仅有利于机器学习的全部领域，也有利于工程的普遍原理。
大多数比随机搜索更复杂的超参数优化算法的一个共同缺点是，他们需要训练实验完整地执行一次才能从该实验中提取信息。从实验早期可以收集的信息量这个角度看来，这个效率是非常低的，因为人工搜索，总是可以很早地确定部分超参数是否完全出问题。Swersky et al. (2014) 引入了一个维护多组实验算法的初始版本。在不同的时间点，超参数优化算法可以选择开始一个新的实验， “冻结”正在运行却不是很有前途的实验，或者“解冻”恢复先前冻结，但是现在有希望得到更多信息的实验。
####1.4	Debugging Strategies 调试策略当一个机器学习系统表现不佳，这通常是很难说表现不佳是因为算法本身的内在还是算法实现中存在错误。有各种原因使得机器学习系统难以调试。
在大多数情况下，我们不能先验地知道算法的预期行为是什么。 事实上，使用机器学习的全局观点就是它会发现我们自己无法指定的有用行为。如果我们在新的分类任务上训练一个神经网络，并且达到了5%的试验错误率。我们并不能直接知道这是预期的表现还是低于最优的表现。
另外一个困难是大多数机器学习模型带有多个自适应的部分。如果一个部分受到破坏，其他部分可以适应并且仍然获得大致可接受的性能。例如，假设我们要训练包含多个隐层的神经网络，其参数为权重W和偏置b。进一步假设，我们分别手动实现了每个参数的梯度下降规则，我们在更新偏置的时候犯了一个错误。
b←b−α 其中α是学习率。这样错误的更新根本不使用梯度，它会导致偏置在学习过程中以固定的速率衰减为负，这显然不是任何有效学习算法的正确实现。只从模型的输出检查该错误可能并不明显。根据输入的分布，权重是能够自适应地去补偿负的偏置。大多数神经网络调试策略的目标是解决这两个难题中的一个或者两个。要么我们设计一个简单的实验，其行为实际上可以预见；要么我们设计一个实验来孤立地测试神经网络的一个部分。一些重要的调试测试包括：
Visualize the model in action （可视化模型行为）当训练模型用于图像中的目标识别时，查看一些图像并与模型提出的检测结果重叠显示。当训练语音生成模型时，试听一些模型生成的语音样本。这似乎是显而易见的，但是很容易陷入只盯着量化性能指标例如精度或似然对数的做法。直接观察机器学习模型在任务上的性能会帮助您确定量化性能指标数字是否合理。评估度量的缺陷可能会是最具破坏性的错误，因为他们可以使你误认为你的系统表现良好，然而并不是。
Visualize the worst mistakes （可视化最严重错误）大多数模型能够输出所执行任务的某种置信度度量。例如，基于softmax的输出层可以为每个类别赋一个概率。所以最有可能的类别获得的概率给出了模型对其分类决定的置信估计。典型地，最大似然估计训练结果给出的这些结果是被高估的，而不是正确预测的准确概率，但是他们（概率值）在某种程度上是有用的，即模型输出概率较小的样本一般是标记不正确的。通过观察训练集中最难以正确分类的样本，可以经常发现数据预处理或者标记的问题。例如。街景转录系统原本有一个问题，地址数字检测系统切图时太紧会忽略某些数字，然后转录神经网络就会为这些图片的正确识别结果赋很低的概率。对图像的识别结果排序找出置信度最高的错误显示了切图存在系统错误。修改后切图系统会裁剪更宽的图像，带来了系统整体性能的提升，尽管转录系统需要能够处理地址数字位置和尺度更大的变化。
Reasoning about software using train and test error （使用训练和测试误差来验证软件）往往很难确定软件的实现是否正确。可以从训练和测试误差获得一些线索。如果训练误差低而测试误差高，那么很有可能训练过程是正确的，而模型由于基本算术的原因产生了过拟合。另一种可能是，测试误差由于种种原因计算错误，可能是因为模型训练后保存又重新加载再进行验证集上的评估，或者是测试集准备的方式与训练集不同。如果训练误差和测试误差都比较高，那么就很难确定是软件存在缺陷还是模型由于基本的算法原因而欠拟合。这样的方案需要进一步的测试，下面描述。
Fit a tiny dataset（小数据集拟合）如果你碰见训练集上的错误率较高，确定是由于真正的欠拟合还是软件缺陷。通常情况下即使是小模型也能够保证在足够小的数据集上拟合。例如，一个仅有单例的分类训练数据集，只是正确设置输出层的偏置就可以拟合。通常，如果不能训练 一个分类器正确分类单一的样本，一个自动编码器不能高保真的重现一个例子，或者一个生成模型对一个样本生成连续的类似采样，那么说明存在软件缺陷在阻止训练集上的成功优化。这样的测试也可以扩展到包含多个样本的小数据集。Compare back-propagated derivatives to numerical derivatives （比较梯度微分和数值微分）如果您正在使用的软件框架需要你自己实现梯度的计算，或者你要添加新的操作到一个微分框架并且必须定义bprop算法，那么一个常见的错误来源是梯度表达式实现错误。一个验证这些微分是否正确的方法是比较你实现的自动微分和有限差分计算的微分。因为微分的形式如下，
我们可以通过有限步长来近似微分。我们还可以通过中心微分来提高近似的精度。扰动大小必须选择得足够大，确保扰动不会被有限精度的数值计算向下舍掉太多。
通常情况下我们要测试向量函数g的梯度或者雅可比矩阵。然而不幸的是，有限差分每次仅允许计算单一的导数。我们可以执行有限微分mn次来评估g的所有偏微分，或者我们可以在新的函数上进行测试，这个函数由g的输入和输出进行随机映射得到。例如，我们可以在f(x)的微分实现上进行测试，其中f (x) = uT g(vx) ，u和v是随机选择的向量。计算 f(x)的微分需要从g正确地执行反向传播，因为只需要计算单一输入和单一输出所以效率很高。重复地对不同的u和v进行实验是一个不错的主意，这降低了测试忽视了与正交于随机投影错误的几率。
如果了解复数的数值计算，那么有一个非常有效的方法来估计以复数作为输入的函数的梯度(Squire and Trapp, 1998)。该方法基于如下的观察，其中i=-1的平方根。不同于上述实数的例子，对于不同点的f求导不会产生相消效应。这使得e可以使用非常小的值，例如10-150，出于实用目的使得误差项的影响可以忽略不计。
Monitor histograms of activations and gradient （监视梯度和激励直方图）通过收集大量的训练迭代统计数据（可能是全部训练样本执行一次），来可视化神经网络的激活和梯度的统计特征是非常有用的。隐单元激活前的值可以告诉我们该单元是否饱和，或者他们饱和的频率。例如，对于激励函数，它们关闭的频率，有经常关闭的单元吗？对于tanh单元，预激活绝对值的均值可以告诉我们该单元的饱和程度。在深度神经网络模型中，反向传播梯度快速提升或者消失时，优化很有可能受到妨碍。最后，比较参数梯度和参数本身的幅值是非常有用的。正如Bottou（2015）的建议，我们希望一个minibatch下参数更新的幅值是参数幅值的1%，而不是50%或者0.001%（这时参数更新太慢）。很可能参数集中的一些参数更新的速度合适而其他却停滞不前。当数据非常稀疏时（例如自然语言处理），一些参数很少更新，当检测他们变化时应该熟记于心。最后，许多深度学习算法提供了每一步产生结果的某种保证。在第三章，我们将看到一些通过袋鼠工具来解决优化问题的近似推理算法。其中一些优化算法保证了目标函数在算法执行一步之后不会增加，在算法执行每一步之后变量集中一些变量的梯度为零，在收敛时所有变量的梯度为零。通常由于舍入误差，数字计算机不会完全满足这些条件，所以调试试验应当包括一些宽容参数。####1.5	Example: Multi-Digit Number Recognition 例子：多位数字识别为了提供如何在实践中运用我们方法论的完整描述，从设计深度学习组件的角度，我们提供了一个街景转录系统简要介绍。显然，整个系统的许多其他组件，如街景车，数据库基础设施等等，也是极其重要的。
从机器学习任务的角度，处理流程开始于数据收集。采集车收集原始数据，同时人工操作员打标。转录任务的开始需要大量数据的收集与加工，包括在转录前使用其他机器学习技术来检查地址数字。转录系统开始于性能评估度量的选择和这些度量的预期值。一个重要的总原则是根据项目的业务目标来定制性能度量的选择。因为地图只有在精确时才有用，所以对该项目设置一个高精度要求非常重要。具体地，目标是获得媲美人工的98%准确率。
这种精度并不总是容易取得的。为了达到这样的精度，街景转录系统牺牲了覆盖率。所以覆盖率称为了项目中优化的主要性能度量，而同时保证98%的准确率。随着卷积神经网络的进步，有可能降低置信度阈值，低于这个阈值网络会拒绝做出预测，而最超过了95%的目标覆盖率。
在选择量化目标后，我们推荐方法论的下一个步骤是迅速建立灵敏的基线系统。对于机器视觉任务，这意味着带有修正线性单元（ReLu）的卷积网络。转录系统开始于这样的模型。当时，卷积神经网络输出序列预测并不常见。为了尽可能地从最简单的基线模型开始，输出层的第一个实现包含了N个不同的softmax单元来预测包含N个字符的序列。这些softmax单元与分类任务的训练方式完全一样，且每个softmax单元独立训练。
我们推荐的方法是反复优化基线和测试每个更改是否有性能提升。街景转录系统的第一个变化是由覆盖率性能度量的理论理解和数据的内在结构激励的。具体地，神经网络拒绝对输入X做出预测如果输出的序列概率小于某些阈值p(y | x) < t 。初始时，p(y | x) 是特别定义的，简单地将所有softmax的输出相乘。这促使一个专门的输出层和计算对数似然概率损失函数的建立。这种方式使得样本拒绝机制更加有效地发挥作用。
至此，覆盖率仍然低于90%，然而目前的方式并不存在明显的理论问题。因此，我们建议的方法是测量训练集与测试集上的表现来确定问题到底是过拟合还是欠拟合。在此例子中，训练误差和测试误差几乎是一样的。实际上，项目开展如此顺利的主要原因是可以利用包含千万级标签样本数据的数据集。因为训练误差和测试误差如此接近，这表明问题既不是过拟合也不是欠拟合。我们推荐的一种调试策略是可视化最严重的误差。在这种情况下，意味着可视化模型给出置信度最高的错误转录的训练样本。这证明大多数这样的例子都是由于输入图像被裁剪地太窄，其中一些地址包含的数字被裁剪操作剪切掉了。例如，包含地址“1849”的图像可能被裁剪地太窄而仅剩“849”可见。这个问题如果从提高负责决定检测区域的地址数字检测系统的准确率入手，可能需要花费数周来解决。相反，团队采用了更有效的决定，简单地扩大裁剪区域，系统地比地址数字检测系统的预测更宽。这样单一的改变使得转录系统的覆盖率提升了10个百分点。
最终，性能提升的最后几个百分点来自于超参数调优。这主要包括提升模型尺寸的同时在其计算成本上维持一定的限制。由于训练和测试误差保持大致相等，这明确地表示任何性能缺陷都是由于欠拟合，以及数据集本身的一些遗留问题。
总而言之，转录系统获得了巨大的成功，其允许数以百万计的地址以人工努力不可能达到的速度和更低的成本被转录。
我们希望，这一章中介绍的设计原则能过带来更多类似的成功。
