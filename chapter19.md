##第十九章：近似推理（Approximate inference）许多概率模型因难以在其中执行推断过程而难以训练。在深度学习的上下文中，我们通常有一组可见变量v和一组隐变量h。推理的挑战通常指的是计算p（h | v）或考虑其期望较困难的问题。这样的操作对于诸如最大似然学习的任务通常是必要的。
许多只具有一个隐层的简单图模型，例如受限波尔兹曼机和概率PCA，以使得像例如计算p（h | v）的推理操作或求其期望以简单的方式来定义。然而不幸的是，大多数具有多层隐变量的图模型包含棘手的后验分布。在这些模型中精确推理需要指数级的时间。甚至一些只有单层的模型也有这个问题，如稀疏编码。
在本章中，我们介绍了几种处理这些棘手的推理问题的技术。稍后，在第20章中，我们将描述如何使用这些技术来训练否则将是难以处理的概率模型，例如深度置信网和深波尔兹曼机。
深层学习中的棘手推理问题通常来自结构化图模型中隐变量间的相互作用。参见图19.1中的示例。这些相互作用可能是由于无向模型中的直接相互作用，或者在有向模型中相同可见单元祖先之间的“解去”(explaining away)相互作用。
（注：explaining away指的是这样一种情况：对于一个多因一果的问题，假设各种“因”之间都是相互独立的，如果已经确定了是因为其中一种原因导致了结果，那么因为其他原因导致了该结果的概率就会下降。
在现实生活中也可以找到这样的例子：假设房子倒塌的可能性包括地震和恐怖袭击，如果我们发现房子倒了，那么很有可能发生了两者中的一个，但如果我们知道是恐怖分子用飞机撞倒的，那么我们就无法判断是不是发生了地震。这时地震的概率就从“很可能”变回了“有可能”，概率降低了，这就是explaining away。
http://blog.csdn.net/huangbo10/article/details/23091083）图19.1：深层学习中的棘手推理问题通常是结构化图模型中隐变量之间相互作用的结果。这些可能是由于边缘直接将一个隐变量连接到另一个，或者由于当观察V结构的子节点时激活更长的路径。（左）半限制玻尔兹曼机（Osindero和Hinton，2008）隐单元之间的连接。隐变量之间的这些直接连接使后验分布难以处理，这是由于隐变量构成的大团体。（中）由于层之间的连接，组织成没有层内连接的变量层的深玻尔兹曼机仍然具有难以处理的后验分布。（右）这个有向模型在观察可见变量时具有隐变量间的相互作用，因为每两个隐变量是共同父。一些概率模型能够提供对隐变量的可控推断，尽管具有上述图形结构之一。如果条件概率分布被选择以引入超出图中所描述的那些额外独立性，则这是可能的。例如，概率PCA具有右图所示的图结构，但由于其使用的特定条件分布（具有相互正交的基矢量的线性高斯条件）的特殊性质，仍然具有简单的推断。###19.1	将推理作为优化（Inference as Optimization）许多处理困难推理问题的方法利用了可以将精确推断描述为优化问题的观点。然后可以通过近似最优化问题推导近似推理算法。
为了构建该优化问题，假设我们有一个由观测变量v和隐变量h组成的概率模型。我们想计算观测数据的对数概率，log p（v;θ）。有时，如果边缘化h的计算代价较大，则计算log p（v;θ）太困难了。相反，我们可以在logp（v;θ）上计算下界L（v，θ，q）。这个界限被称为证据下界（ELBO，evidence lower bound）。该下界的另一常用名称是负变化自由能。具体来说，证据下界定义为其中q是h上的任意概率分布。因为logp（v）和L（v，θ，q）之间的差异由KL散度给出，并且因为KL散度总是非负的，所以我们可以看到L最多有与期望对数概率相同的值。当且仅当q与p（h | v）具有相同的分布时，这两个值是相等的。令人惊讶的是，对于一些分布q，L可以相当容易地计算。简单的代数表明，我们可以将L重新排列成更方便的形式：这产生了证据下界的更规范的定义，对于适当选择的q，L是易于计算的。对于q的任何选择，L提供了似然的下界。对于是p（h | v）的更好近似的q（h | v），下界L将更紧密，换句话说，更接近logp（v）。当q（h | v）= p（h | v）时，近似是完美的，即L（v，θ，q）= log p（v;θ）。
因此，我们可以将推理认为是找到使L最大的q的过程。精确推理通过在包括p（h | v）的函数族q上搜索来完美地最大化L。在本章中，我们将演示如何通过使用近似优化来找到q来导出不同形式的近似推理。我们可以使优化过程更容易，但是通过限制允许优化被搜索的分布族，或者通过使用可能不完全最大化L但仅仅将其显著增加的不完美优化过程来近似。
无论我们选择使用什么样的q，L是下界。根据我们如何处理这个优化问题的选择，计算会更便宜或者更昂贵，我们也可以得到更紧凑或更宽松的界限。我们可以获得匹配不佳的q，但通过使用不完美的优化过程或通过在有限的q分布族上使用完美的优化过程来减少计算成本。###19.2	期望最大化（Expectation Maximization）我们基于最大化下界L引入的第一个算法是期望最大化（EM）算法，一种用于具有隐变量的模型的流行训练算法。我们在这里描述由Neal和Hinton（1999）开发的EM算法的视图。与我们在本章中描述的大多数其他算法不同，EM不是近似推理的方法，而是一种用近似后验学习的方法。
EM算法包括在两个步骤之间交替进行直到收敛：
*	E步骤（期望步骤）：令θ（0）表示开始步骤时的参数值。对于要训练的训练样本v（i）的所有索引i设置q（h（i）| v）= p（h（i）| v（i）;θ）（batch和minibatch）。通过这个，我们的意思是根据θ（0）的当前参数值来定义q; 如果我们改变θ，则p（h | v;θ）将改变，但是q（h | v）将保持等于p（h | v;θ（0））。*	M步骤（最大化步骤）：相对于θ使用您选择的优化算法，完全或部分最大化，这可以被视为一个坐标上升算法来最大化L。在一步上，我们相对于q最大化L，另一方面，我们相对于θ最大化L。
在隐变量模型上的随机梯度上升可以被看作EM算法的特殊情况，其中M步骤包括采用单个梯度步骤。EM算法的其他变体可以做出更大的步骤。对于一些模型族，M步甚至可以分析地执行，跳到一直到给定当前q的θ的最优解。
即使E步骤涉及精确推理，我们可以认为EM算法在某种意义上使用了近似推理。具体地，M步骤假设相同的q值可以用于所有的θ值。这将随着M步逐渐远离在E步中使用的θ（0）值而在L和真实log p（v）之间引入间隙。幸运的是，当我们进入下一次循环时，E步骤再次将间隙减小到零。
EM算法包含几个不同的洞察。首先，在学习过程的基本过程中，我们更新模型参数以提高整个数据集的似然，其中所有缺失变量的值由后验分布的估计提供。这种特殊的洞察力并不是EM算法所独有的。例如，使用梯度下降以最大化对数似然也具有相同的属性;对数似然梯度计算需要相对于隐单元的后验分布求取期望。在EM算法中的另一个关键的洞察是，即使在我们移动到不同的θ值之后，我们仍然可以继续使用一个相同的q值。这种特殊的洞察在整个经典机器学习中被用来导出大的M步骤更新。在深度学习的上下文中，大多数模型太复杂，不能容纳一个最佳大M步更新的可控的解决方案，因此很少使用EM算法中更独特的第二个洞察。
###19.3	最大后验推理和稀疏编码（MAP Inference and Sparse Coding）我们通常使用术语“推理”来指代给定另一个变量时计算一组变量的概率分布。当训练包含隐变量的概率模型时，我们通常对计算p（h | v）感兴趣。 另一种推断形式是计算缺失变量的单个最可能的值，而不是推断其可能值上的整个分布。在隐变量模型的上下文中，这意味着计算，这被称为最大后验推理，缩写为MAP推理。
MAP推理通常不被认为是近似推理——它计算h*最可能的确切值。然而，如果我们希望基于最大化L（v，h，q）来开发学习过程，则将MAP推理认为是提供q值的过程是有帮助的。在这个意义上，我们可以认为MAP推理是近似推理，因为它不提供最优q。
回想章节19.1中，精确推理包括使用精确优化算法，相对于无限制概率分布族q最大化，我们可以通过限制分布族q来推导MAP推理作为近似推理的形式。 具体来说，我们需要q来处理狄拉克（Dirac）分布：这意味着我们现在可以通过μ完全控制q。 丢弃L的项不随μ变化，我们留下优化问题，这等价于MAP推理问题，因此，我们可以证明类似于EM的学习过程，其中我们在执行MAP推理之间交替以推断h *，然后更新θ以增加logp（h *，v）。与EM一样，这是在L上的坐标上升的形式，其中我们在相对于q使用推理来优化L和相对于θ使用参数更新来优化L之间交替。作为整体的过程可以通过L是log p（v）的下界的事实来证明。在MAP推理的情况下，这种理由是相当空虚的，因为由于狄拉克分布的负无穷大的微分熵，界限（bound）是无限宽的。然而，向μ添加噪声将使界限（bound）再次有意义。
在深度学习中，MAP推理即做为特征提取也作为学习机制来使用。它主要用于稀疏编码模型。
回想一下章节13.4，稀疏编码是一个线性因子模型，在其隐单元上施加稀疏诱导先验。一个常见的选择是阶乘拉普拉斯先验，然后通过执行线性变换和添加噪声来生成可见单元：计算p（h | v）是困难的，甚至表示也是。每对变量hi和hj都是v的父节点。这意味着当观察到v时，图模型包含连接hi和hj的活动路径。所有隐单元因此参与在p（h | v）中的一个大规模团体。如果模型是高斯型，则这些相互作用可以通过协方差矩阵有效地建模，但是稀疏先验使这些相互作用是非高斯形式的。
因为p（h | v）是难以处理的，所以对数似然及其梯度的计算也是如此。 因此，我们不能使用精确的最大似然学习。 相反，我们使用MAP推理，并通过最大化由Dirac分布在h的MAP估计周围定义的ELBO来学习参数。
如果我们将训练集中所有的h个向量连接成矩阵H，则稀疏编码学习过程包括最小化，稀疏编码的大多数应用还涉及权重衰减或对W的列范数的约束，以便防止具有极小H和极大W的病态的解。
我们可以通过在相对于H的最小化和相对于W的最小化之间交替来最小化J。两个子问题都是凸的。事实上，相对于W的最小化只是一个线性回归问题。然而，关于两个参数的J的最小化通常不是凸问题。关于H的最小化需要专门的算法，例如特征符号搜索算法（Lee等人，2007）。###19.4	 变分推理和学习（Variational Inference and Learning）我们已经看到证据下界L（v，θ，q）如何是logp（v;θ）的下界，如何推理可以被看作相对于q最大化L，以及如何将学习看作相对于θ最大化L。我们已经看到，EM算法允许我们用固定的q进行大的学习步骤，并且基于MAP推理的学习算法允许我们使用p（h | v）的点估计来学习，而不是推断整个分布。现在我们开发更一般的变分学习方法。
变分学习背后的核心思想是可以通过一个严格受限的q分布族来最大化L。这个族的选择应该使得Eq logp（h，v）容易计算。一个典型的方法是引入关于q如何因式分解的假设。
变分学习的一种常用方法是强加限制，即q是因子分布：这被称为平均场方法。更一般地，我们可以在q上强加我们选择的任何图模型结构，以灵活地确定我们想要我们的近似捕获多少交互。这种完全一般的图模型方法称为结构变分推理（structured variational inference）（Saul和Jordan，1996）。
变分法的美妙之处在于，我们不需要为q指定具体的参数形式。我们指定应该如何因式分解，但之后优化问题确定在哪些因式分解约束内的最佳概率分布。对于离散隐变量，这仅仅意味着我们使用传统的优化技术来优化描述q分布的有限数量的变量。对于连续隐变量，这意味着我们使用称为变分微积分的数学分支来对函数空间执行优化，并且实际确定应该使用哪个函数来表示q。变分微积分是名词“变分学习”和“变分推理”的起源，尽管这些名称也适用，即使隐变量是离散的，并且不需要变化的微积分。在连续隐变量的情况下，变分微积分是一种强大的技术，可以从模型的人类设计者中消除许多责任，他们现在必须仅指定q的因式分解，而不需要猜测如何设计特定的q可以准确地近似后验。
因为L（v，θ，q）定义为logp（v;θ）-DKL（q（h | v）||p（h | v;θ）），我们可以认为相对于q最大化DKL（q（h | v）||p（h | v））。
在这个意义上，我们拟合q。 然而，我们这样做与KL散度的方向相反，我们习惯于使用拟合近似。当我们使用最大似然学习将模型拟合到数据时，我们最小化DKL（pdata||pmodel）。如图3.6所示，这意味着最大似然鼓励模型在数据具有高概率的任何地方具有高概率，而我们的基于优化的推理过程鼓励q具有低概率，其中真实后验具有低概率。KL发散的两个方向都具有所期望的和不期望的性质。选择使用哪一个取决于哪些属性是每个应用程序的最高优先级。在推理优化问题的情况下，出于计算的原因，我们选择使用DKL（q（h | v）||p（h | v））。具体来说，计算D KL（q（h | v）||p（h | v））涉及评估关于q的期望，因此通过将q设计为简单，可以简化所需的期望。KL发散的相反方向将需要相对于真实后验的计算期望。因为真实后验的形式是由模型的选择决定的，我们不能设计一个降低成本的方法来确切计算DKL（p（h | v）||q（h | v））。
####19.4.1	离散隐变量（Discrete Latent Variables）使用离散隐变量的变分推理是相对直接的。我们定义一个分布q，通常是q中的每个因子恰好由离散状态下的查找表定义。在最简单的情况下，h是二元的，我们使用平均场假设即q因子分解到每个hi。在这种情况下，我们可以用一个元素是概率的向量h来参数化q。然后有q（hi = 1 | v）= hi。
在确定如何表示q之后，我们可以轻松优化其参数。在离散隐变量的情况下，这只是一个标准优化问题。原则上，q的选择可以用任何优化算法来完成，例如梯度下降法。
因为这种优化必须发生在学习算法的内循环中，所以必须非常快。为了达到这种速度，我们通常使用专门的优化算法，这些算法用于在非常少的迭代中解决相对较小和简单的问题。一个流行的选择是迭代固定点方程，换句话说，针对hi来解决，我们反复更新h的不同元素，直到我们满足收敛标准。
为了使（上述概念）这更具体，我们展示了如何应用变分推理到二进制稀疏编码模型（我们在这里展示了Henniges等人（2010）开发的模型，但演示的是应用传统的通用平均场于模型，而他们引入了专用算法）。这种推导引入了相当多的数学细节，并且旨在给希望完全解决我们迄今提出的关于变分推理和学习的高级概念描述中任何模糊性的读者。不计划推导或使用变分学习算法的读者可以安全地跳到下一部分，而不丢失任何新的高级概念。鼓励继续进行二进制稀疏编码示例的读者查看在第二章概率模型中经常出现的章节3.10中函数有用属性的列表。我们在以下推导中使用这些属性，而不突出显示我们使用每个属性的位置。
在二进制稀疏编码模型中，通过向m个不同分量的和加入高斯噪声来从模型生成输入v∈Rn，其中m个不同分量可以各自存在或不存在。每个元素由m中h∈{0,1}的相对应隐单元打开或关闭：其中b是可学习的偏置集合，W是可学习的权重矩阵，并且β是可学习的对角精度矩阵。
以最大似然训练该模型需要相对于参数求导数。考虑关于其中一个偏差的导数：这需要相对于p(h | v)计算期望。然而p(h | v)是一个复杂的分布，参见图19.2所示的p(h, v)和p(h | v )的图结构。后验分布对应于隐单元上的完整图，因此变量消除算法不能帮助我们计算所需期望所使用的时间比蛮力更少。图19.2：包含隐单元的二进制稀疏编码模型的图结构。（左边）p(h, v)的图结构。注意其中的边是有向的，并且每两个隐单元是每个可见单元的共同父母。（右边）p(h | v )的图结构，为了解释共同父母之间的活动路径，后验分布需要任意两个隐单元间之间的边。我们可以通过使用变分推理和变分学习来解决这个困难。我们可以做一个平均场近似：二进制稀疏编码模型的隐变量是二进制的，因此为了表示阶乘q，我们只需要对m个伯努利分布q（hi | v）建模。表示伯努利分布的平均值的自然方式是使用概率的向量h，其中q（hi=1|v）= hi。我们施加限制使hi不会等于0或者1，以便在计算时避免错误，例如计算log hi。
我们将看到变分推理方程式从不将hi置为0或1。然而，在软件实现中，机器舍入误差可能导致0或1的值。在软件中，我们可能希望使用变分参数z的非限制向量来实现二进制稀疏编码，并且通过关系h =σ（z）获得h。因此，我们可以通过使用与sigmoid和softplus相关的标识logσ（zi）=-ζ（-zi）在计算机上安全地计算log hi。我们开始二进制稀疏编码模型中变分学习的推导，我们表明使用这个平均场近似使学习容易处理。
证据下界由下式给出，虽然这些方程在形式上并不太吸引人，但它们表明L可以用少量简单的算术运算来表示。因此，证据下界L是易于处理的。我们可以使用L作为难以处理的对数似然的替代。
原则上，我们可以简单地在v和h上运行梯度上升，这将是一个完美可接受的组合推理和训练算法。然而我们通常不这样做，有两个原因。首先，这将需要为每个v存储h。我们通常不喜欢需要存储每个样本的算法。如果我们必须记住与每个示例相关联的动态更新的向量，则难以将学习算法扩展到数十亿个示例。其次，我们希望能够非常快速地提取特征h，以便识别v的内容。在现实的部署设置中，我们将需要能够实时地计算h。
基于这些原因，我们通常不使用梯度下降来计算平均场参数h。相反，我们使用定点方程快速估计它们。
定点方程背后的想法是我们寻求相对于h的局部最大值，其中∇hL（v，θ，h）= 0。我们不能同时有效地求解关于所有h的该方程。然而，我们可以求解单个变量：然后，我们可以迭代地将该解应用于i = 1，... ，m的方程。并重复该循环直到我们满足收敛标准。公共收敛准则包括当更新的完整周期没有将L提高超过一些容忍差量时，或者当周期不将h改变多于一定量时停止。
迭代平均场固定点方程是可以在多种模型中提供快速变分推理的一般技术。为了更具体，我们将展示如何导出二进制稀疏编码模型的更新。
首先，我们必须写出一个关于hi的导数的表达式。为此，我们将等式 19.36代入方程19.37的左边。为了应用固定点更新推理规则，我们求解将公式19.43设为0的hi：在这一点上，我们可以看到，在循环神经网络和图模型中的推理之间存在紧密的联系。具体来说，平均场固定点方程定义了一个循环神经网络。 这个网络的任务是执行推理。我们已经描述了如何从模型描述得到这个网络，但是也可以直接训练推理网络。基于这个主题的几个想法在第20章中描述。
在二进制稀疏编码的情况下，我们可以看到由等式19.44指定的循环神经网络间的连接由基于相邻隐单元的变化值重复地更新隐单元组成。输入总是向隐单元发送vTβW的固定消息，但是隐单元不断地更新它们彼此发送的消息。具体地，当它们的权重向量对准时，两个单元hi和hj彼此抑制。这是两个隐单元之间的一种竞争形式，它们都解释了输入，只有最能解释输入的隐单元才允许保持活动。这个竞争是平均场近似试图捕获二进制稀疏编码后验中的“解去”相互作用的尝试。“解去”效应实际上应导致多模态后验，使得如果我们从后验抽样，一些样本将具有一个单元活动，其它样本将具有活动的另一单元，但非常少的样本具有活动。不幸的是，“解去”相互作用不能由用于平均场的阶乘q来建模，因此平均场近似被迫选择一种模式来模拟。这是图3.6所示的行为的实例。
我们可以重写公式 19.44为一个等价的形式，进一步揭示一些见解：在这个重构中，我们看到每个步骤的输入包括v − W:,jhj而不是v。因此我们可以认为单元i试图编码给定其他单元的代码的v中的残差。因此，我们可以将稀疏编码视为迭代自动编码器，其重复地编码和解码其输入，试图在每次迭代之后重建中修复错误。
在此示例中，我们已经导出一次更新单个单元的更新规则。能够同时更新更多单元将是有利的。一些图模型，例如深玻尔兹曼机，以这样的方式构造，使得我们可以同时解决h的许多条目。不幸的是，二进制稀疏编码不允许这样的块更新。相反，我们可以使用一种叫做damping的启发式技术来执行块更新。在阻尼方法中，我们求解h的每个元素的单独最优值，然后在该方向上以小步长移动所有值。这种方法不再保证在每个步骤增加L，但在许多模型的实践中工作良好。关于在消息传递算法中选择同步和阻尼策略的程度的更多信息，参见Koller和Friedman（2009）。
####19.4.2	变分微积分（Calculus of Variations）在我们继续演示变分学习之前，我们必须简要介绍变分学习中使用的一组重要的数学工具：变分微积分。
许多机器学习技术基于通过找到使其取最小值的输入向量θ∈Rn来最小化函数J（θ）。这可以通过求解ΘθJ（θ）= 0的临界点而用多元演算和线性代数来完成。在一些情况下，我们实际上想要求解函数f（x），例如当我们想要找到一些随机变量的概率密度函数f(x)。变分微积分使我们能够这样做。
函数f的函数被称为函数J [f]。就像我们可以对其向量值参数的元素取部分导数一样，我们可以对函数f[f]的各个值x取函数J[f]的函数导数，也称为变分导数。相对于点x处的函数f的值，函数J的函数导数表示为δ J /δf(x)。
函数导数的完整正式推导超出了本书的范围。为了我们的目的，对于具有连续导数的可微函数f（x）和可微函数g（y，x），下述公式足以说明，为了获得这个辨识的一些直觉，可以认为f（x）是具有不可数的许多元素的向量，由实向量x索引。在这个（有点不完全的看法）中，提供函数导数的身份与通过用正整数索引的向量θ∈Rn获得的相同：在其他机器学习出版物中的许多结果使用更一般的欧拉——拉格朗日方程来呈现，其允许g取决于f的导数以及f的值，但是本书中对于在这里呈现的结果，我们不需要这个完全一般的形式。
为了相对于向量优化函数，我们取函数相对于向量的梯度，并求解其中梯度的每个元素等于零的点。同样，我们可以通过求解每个点处的函数导数等于零的函数来优化函数。
作为这个过程如何工作的示例，考虑找到具有最大微分熵的x∈R的概率分布函数的问题。回想一下概率分布p（x）的熵定义为对于连续值，期望是一个积分，我们不能简单地相对于函数p（x）最大化H（x），因为结果可能不是概率分布。相反，我们需要使用拉格朗日乘子，以添加一个约束p（x）积分为1。此外，熵增加无边界随方差增加。这使得哪个分布具有最大熵的问题无趣。相反，我们要求哪个分布具有固定方差σ2的最大熵。最后，问题是不确定的，因为分布可以任意改变而不改变熵。为了施加一个独特的解，我们添加一个约束，分布的均值为μ。这个优化问题的拉格朗日函数是为了使相对于p的拉格朗日最小化，我们将函数导数设置为0：这个条件现在告诉我们p（x）的函数形式。通过代数重新排列方程，我们得到,我们从来没有直接假设p（x）将采取这种功能形式; 我们通过分析最小化功能来获得表达式本身。为了解决最小化问题，我们必须选择λ值以确保满足所有的约束。我们可以自由选择任何λ值，因为只要满足约束，拉格朗日相对于λ变量的梯度为零。为了满足所有约束，我们可以设置λ1=logσ，λ2= 0和λ3= -1/2σ2以获得，这是当我们不知道真实分布时使用正态分布的一个原因。因为正态分布具有最大熵，我们通过做这个假设施加最小可能的结构量。在检查熵的拉格朗日函数的临界点时，我们只找到一个临界点，对应于使固定方差的熵最大化。那么最小化熵的概率分布函数呢？为什么我们没有找到对应于最小值的第二个临界点？原因是没有实现最小熵的特定函数。由于函数将更多的概率密度放置在两个点x =μ+σ和x =μ-σ上，并且将较小的概率密度置于x的所有其他值上，所以它们丢失熵，同时保持期望的方差。然而，任何在除两个点之外的所有点上都精确地为零质量的函数不会被整合到一个点，并且不是有效的概率分布。因此，没有单个最小熵概率分布函数，很多时候就像没有单个最小正实数。相反，我们可以说，有一个概率分布的序列收敛到质量只在这两个点。这种退化情景可以被描述为狄拉克分布的混合。因为狄拉克分布不是由单个概率分布函数描述的，所以没有狄拉克或狄拉克分布的混合对应于函数空间中的单个特定点。因此，这些分布对于我们的求解其中函数导数为零的特定点的方法是不可见的。这是该方法的一个缺点。必须通过其他方法找到诸如Dirac的分布，例如猜测解决方案，然后证明它是正确的。
####19.4.3	连续隐变量（Continuous Latent Variables）当我们的图模型包含连续隐变量时，我们仍然可以通过最大化L来执行变分推理和学习。然而，当相对于q（h | v）最大化L时，我们现在必须使用变分微积分。
在大多数情况下，从业者不需要解决任何变化问题本身的微积分。相反，存在用于平均场固定点更新的一般方程。如果我们进行平均场近似，并且针对所有j != i固定q（hj | v），则可以通过获得最优q（hi | v）来归一化非归一化的分布，只要p不为任何联合配置的变量分配0概率。在等式内执行期望将产生q（hi| v）的正确函数形式。如果希望开发新形式的变分学习，则只需要使用变量的微积分直接导出q的函数形式; 等式 19.56可以得到任何概率模型的平均场近似。
等式 19.56是固定点方程，设计为迭代地应用于i的每个值，直到收敛。然而，它也告诉我们更多。它告诉我们最佳解决方案将采取的函数形式，无论我们是否通过定点方程求得。这意味着我们可以从该方程获取函数形式，但将其中出现的一些值视为参数，我们可以使用任何我们喜欢的优化算法进行优化。
以一个非常简单的概率模型为例，隐变量h∈R2和只有一个可见变量v假设p（h）= N（h; 0，I）和p（v | h）= N v; w> h; 1）。我们可以通过对h积分来简化这个模型; 结果只是v上的高斯分布。模型本身并不有趣; 我们构建它只是提供一个变分微积分如何应用于概率建模的简单演示。
通过归一化到一个常数可以给出真正的后验，由于存在将h1和h2相乘的项，我们可以看出真实后验不对h1和h2因式分解。使用公式19.56，我们发现，从这可以看出，我们需要从q（h2 | v）有效获取的只有两个值：Eh2〜q（h | v）[h2]和Eh2〜q（h | v）[h22]。这些写为h2和h22，我们可以获得，从这里，我们可以看到q具有高斯的函数形式。因此，我们可以得出结论q（h | v）= N（h;μ，β-1），其中μ和对角线β是变化参数，我们可以使用任何我们选择的技术进行优化。 重要的是要记住，我们没有假设q将是高斯; 其高斯形式通过使用变化的微积分自动地导出以相对于L最大化q。在不同模型上使用相同的方法可以产生不同的q的函数形式。
这当然是一个为示范目的而构建的小案例。关于在深度学习背景下变量学习与连续变量的真实应用的例子，参见Goodfellow et al。 （2013d）。
####19.4.4	学习和推理之间的相互作用（Interactions between Learning and Inference）使用近似推理作为学习算法的一部分会影响学习过程，这反过来影响推理算法的准确性。
具体来说，训练算法倾向于以使得近似推理算法下面的近似假设变得更真实的方式来适应模型。当训练参数时，变分学习增加，对于特定v，这对于在q(h|v)下具有高概率的h的值增加p(h|v)，并且对于在q(h|v)处具有低概率的h的值减小p(h|v)。
这种行为使我们的近似假设成为自我实现的预言。如果我们用单模近似后验训练模型，我们将获得一个真实后验的模型，该模型比我们通过用精确推理训练模型获得的模型更接近单峰。
因此，通过变分近似计算施加在模型上的真实伤害量是非常困难的。存在用于估计log p（v）的若干方法。我们经常在训练模型之后估计log p（v;θ），并发现其与L（v，θ，q）的间隙很小。由此，我们可以得出结论，我们的变分近似对于从学习过程获得的θ的具体值是精确的。我们不应该得出结论，我们的变分近似一般是准确的，或者变分近似对学习过程没有什么害处。为了测量由变分近似引起的真实伤害量，我们需要知道θ* =maxθlog p（v;θ）。可以同时保持L（v，θ，q）≈logp（v;θ）和logp（v;θ）<< logp（v;θ*）。如果maxqL（v，θ*，q）<< logp（v;θ*），因为θ*太复杂使得我们的q族难以捕获后验分布，则学习过程将永远不会接近θ*。这样的问题很难检测，因为我们只能知道它发生了，如果我们有一个优秀的学习算法可以找到θ*来比较。
###19.5	学习的近似推断（Learned Approximate Inference）我们已经看到推理可以被认为是增加函数L的值的优化过程。通过诸如定点方程或基于梯度的优化的迭代过程显式地执行优化通常是非常昂贵和耗时的。许多推理方法通过学习执行近似推断来避免这种花费。具体来说，我们可以将优化过程想象为将输入v映射到近似分布q * = arg maxq L（v，q）的函数f。一旦我们认为多步迭代优化过程只是一个函数，我们可以用一个实现近似f（v;θ）的神经网络来近似它。
####19.5.1	唤醒睡眠（Wake-Sleep）训练模型以从v推断h的主要困难之一是我们没有用来训练模型的监督训练集合。给定v，我们不知道适当的h。从v到h的映射取决于模型族的选择，并且在整个学习过程中随着θ变化而演变。
唤醒睡眠算法（Hinton等人，1995b; Frey等人，1996）通过从模型分布中绘制h和v的样本来解决这个问题。例如，在有向模型中，这可以通过执行从h开始并在v结束的祖先采样来廉价地完成。然后可以训练推断网络以执行反向映射：预测哪个h导致了当前v。这种方法的主要缺点是我们将只能够训练推理网络在模型下具有高概率的v值。在学习早期，模型分布将不像数据分布，因此推理网络将不具有学习类似数据的样本的机会。
在章节18.2我们看到睡眠中做梦在人类和动物中的作用的一个可能的解释是，梦境可以提供蒙特卡罗训练算法用于近似无向模型的对数分割函数的负梯度的负相位样本。生物作梦的另一个可能的解释是，它提供来自p（h，v）的样本，其可以用于训练推理网络在给定v的情况下预测h。在某些意义上，该解释比分区函数的解释更令人满意。蒙特卡洛算法通常表现不好，如果它们仅使用梯度的正相位进行几个步骤，然后仅对梯级的负相位进行几个步骤。人类和动物通常醒来连续几个小时，然后睡着连续几个小时。这个时间表如何支持无向模型的蒙特卡罗训练并不明显。然而，基于最大化L的学习算法可以延长的改善q的周期和延长的改善θ的周期运行。如果生物作梦的作用是训练预测q的网络，那么这解释了动物如何能够保持清醒几个小时（它们醒来的时间越长，L和log p（v）之间的差距越大，但是L仍然将是下界）并且保持睡眠几个小时（生成模型本身在睡眠期间不被修改），而不损害它们的内部模型。当然，这些想法纯粹是投机性的，没有任何坚实的证据表明梦境实现了这些目标之一。梦境也可以服务强化学习而不是概率建模，通过从动物的转移模型采样合成经验，在其上训练动物的策略。或睡眠可以服务于机器学习社区尚未预期的一些其他目的。
####19.5.2	其他形式的学习推断（Other Forms of Learned Inference）这种学习近似推理的策略也已经应用于其他模型。Salakhutdinov和Larochelle（2010）表明，在一个学习的推理网络中的单次通过可以产生比在DBM中迭代平均场固定点方程更快的推理。训练过程基于执行推理网络，然后应用一步平均场来改进其估计，并训练推理网络以输出这个精确估计而不是其原始估计。
我们已经在章节14.8了解到预测稀疏分解模型训练浅编码器网络以预测输入的稀疏编码。这可以被看作是自编码器和稀疏编码之间的混合。可以为模型设计概率语义，在该概率下，编码器可以被视为执行学习的近似MAP推断。由于其浅编码器，PSD不能实现我们在平均场推理中看到的单元之间的那种竞争。然而，该问题可以通过训练深度编码器来执行学习的近似推理来补救，如在ISTA技术中（Gregor和LeCun，2010b）。
学习近似推理最近已成为生成式建模的主要方法之一，以变分自动编码器的形式（Kingma，2013; Rezende et al.，2014）。在这种优雅的方法中，不需要为推理网络构建明确的目标。相反，推理网络简单地用于定义L（此处原书有笔误），不需要推理网络适应地增加L。这个模型在后面的章节20.10.3中会深入描述。
使用近似推理，可以训练和使用各种各样的模型。其中许多模型将在下一章中描述。