##第十七章：蒙特卡洛方法（Monte Carlo Methods）随机算法分为两大类：拉斯维加斯算法和蒙特卡罗算法。拉斯维加斯算法总是精确地返回正确答案（或报告他们失败）。这些算法消耗随机数量的资源，通常是内存或时间。相比之下，蒙特卡罗算法返回具有随机误差量的答案。通常可以通过花费更多资源（通常是运行时间和内存）来减少错误量。对于任何固定的计算预算，蒙特卡罗算法可以提供近似答案。
机器学习中的许多问题是如此困难，以至于我们永远不能期望获得精确的答案。这不包括精确的确定性算法和拉斯维加斯算法。相反，我们必须使用确定性近似算法或蒙特卡罗近似。这两种方法在机器学习中是普遍存在的。在本章中，我们关注蒙特卡罗方法。
###17.1	采样和蒙特卡洛方法（Sampling and Monte Carlo Methods）用于实现机器学习目标的许多重要技术是基于从一些概率分布抽取样本，并使用这些样本形成一些期望数量的蒙特卡罗估计。####17.1.1	为什么采样？（Why Sampling）有很多原因促使我们可能希望从概率分布中抽取样本。采样提供了一种以降低的成本来近似多种求和与求积分的灵活方法。有时候，我们使用它来加速处理代价较大但是可控的（成本）总和，就像我们用minibatches对整个训练成本进行下采样的情况。在其他情况下，我们的学习算法需要我们近似一个难以处理的和或积分，例如一个无向图模型的log分区函数的梯度。在许多其他情况下，抽样实际上是我们在想训练一个可以从训练分布中抽样的模型的意义之上的目标。####17.1.2	蒙特卡洛采样的基础（Basics of Monte Carlo Sampling）当无法精确计算和或积分（例如，求和包含指数项的，并且未知精确的简化）时，通常可以使用蒙特卡洛采样来近似它。这个想法是查看和或积分，如同它是一个分布下的期望值，并通过相应的平均值来近似期望值（approximate the expectation by a corresponding average）。 让或者作为估计的总和或整数，重写为期望，其中p是概率分布（对于和）或者对于随机变量x的概率密度（对于积分）。
我们可以通过从p抽样n个样本x（1），...，x（n）来近似s，然后形成经验平均值。这种近似由几个不同的性质证明。 第一个观察是，该估计量是无偏的，因为但是另外，大数定律说明如果样本x（n）的i.i.d的，那么平均值会可靠地收敛到期望值：条件是单个项的方差Var [f（x（i））]有界。为了更清楚地看到这一点，考虑sn的方差随着n增加。方差Var [sn]减小并收敛到0，只要Var [f（x（i））] <∞：这个方便的结果还告诉我们如何估计蒙特卡洛平均值中的不确定性或者等价地估计蒙特卡罗近似的预期误差量。我们计算f（x）的经验平均值和它们经验方差，然后将估计方差除以样本数量n以获得Var [sn]的估计。中心极限定理告诉我们，平均值sn的分布收敛到具有均值s和方差Var [f（x）]的正态分布。这允许我们使用正态密度的累积分布来估计sn周围的置信区间。
然而，所有这些依赖于我们从基本分布p（x）轻松采样的能力，但这样做并不总是可能的。当从p中采样不可行时，另一种方法是使用重要性采样，如章节17.2所述。更一般的方法是形成向感兴趣的分布收敛的估计序列。这是蒙特卡洛马尔可夫链方法（第17.3节）。
###17.2	重要性采样（Importance Sampling）等式17.2中蒙特卡洛方法中使用的被积函数（或被加数）分解的一个重要步骤是，确定被积函数的哪一部分应该起到概率p（x）的作用，并且被积函数的哪一部分应该起到其期望值（在该概率分布下）被估计的定量函数f（x）的作用。没有唯一分解，因为p（x）f（x）总是可以重写为，其中我们现在从q和平均值pf/q采样。在很多情况下，我们希望计算给定的p和f的期望，以及从开始该问题作为期望的事实即表明该p和f将是分解的自然选择。然而，问题的原始规范可能不是在获得给定精度水平所需的样本数量方面的最佳选择。幸运的是，最佳选择q*的形式可以很容易导出。最优q*对应于所谓的最优重要性采样。由等式 17.8，可以将任何蒙特卡洛估计，变换为重要性采样估计。我们很容易看到估计量的期望值不取决于q：然而，重要性采样估计量的方差可能对q的选择非常敏感。方差由下式给出，当q为下式时，出现最小方差，其中Z是归一化常数，选择使得q*（x）适当地求和或积分到1。更好的重要性采样分布在被积函数较大的地方权重更大。事实上，当f（x）不改变符号时，Var [sq *] = 0，这意味着当使用最优分布时单个样本就足够了。当然，这只是因为q*的计算已经基本上解决了原始问题，因此使用这种从最佳分布绘制单个样本的方法通常是不实际的。
抽样分布的任何选择q是有效的（在产生正确的期望值的意义上），q *是最佳的（在产生最小方差的意义上）。从q *抽样通常是不可行的，但q的其他选择可以非常灵活，同时仍然稍微减少方差。
另一种方法是使用偏置重要性采样，其具有不需要归一化的p或q的优点。在离散变量的情况下，偏置重要性抽样估计量由下式给出，其中p和q是p和q的非归一化形式，x（i）是来自q的样本 这个估计量是有偏差的，因为E [sBIS]不等于s，除非渐近地当n→∞和公式的分母等式17.14收敛于1。因此，该估计被称为渐近无偏的。
虽然一个好的q的选择可以大大提高蒙特卡洛估计的效率，不良的q选择可以使效率更糟。回到公式17.12，我们看到如果存在q的样本，其中p（x）| f（x）/ q（x）是大的，则q（x）估计量的方差可能变得非常大。这可能发生在q（x）很小，而p（x）和f（x）都不足以抵消它时。q分布通常选择为非常简单的分布，以便容易从中进行采样。当x是高维度时，q的这种简单性使其匹配p或p | f |不好。当q（x（i））远大于p（x（i））| f（x（i））|时，重要性采样收集无用样本（求微小数或零）。另一方面，更少发生的情况是当q（x（i））远小于p（x（i））| f（x（i））|时，这个比率可能是巨大的。因为这些后面的事件是罕见的，它们可能不出现在典型的样本中，产生s的典型低估，很少被大量过高估计补偿。当x是高维度时，这种非常大或非常小的数是典型的，因为在高维度中，关联概率的动态范围可能非常大。
尽管存在这种危险，重要性采样及其变体已被发现在许多机器学习算法中非常有用，包括深度学习算法。例如，参见使用重要性采样来加速具有大词汇量（12.4.3.3节）的神经语言模型或其他具有大量输出的神经网络的训练。另见章节18.7中如何使用重要性采样来估计分段函数（概率分布的归一化常数）。和章节20.10.3中在深度有向模型（例如变分自动编码器）中估计对数似然。重要性采样还可以用于改进训练具有随机梯度下降的模型参数的损失函数的梯度估计，特别是对于诸如分类器的模型，其中损失函数的大部分总值来自少量的错误分类例子。更频繁地采样更难处理的例子可以减少这种情况下梯度的方差（Hinton，2006）。
###17.3	马可夫链蒙特卡洛方法（Markov Chain Monte Carlo Methods）在很多情况下，我们希望使用蒙特卡洛技术，但是没有用于从分布pmodel（x）或从良好（低方差）重要性采样分布q（x）中绘制精确采样的易处理方法。在深度学习的上下文中，这通常发生在pmodel（x）由无向模型表示时。在这些情况下，我们引入一个称为马尔可夫链的数学工具来近似从pmodel（x）取样。使用马尔科夫链执行蒙特卡罗估计的算法族被称为马尔可夫链蒙特卡罗方法（MCMC）。用于机器学习的马尔可夫链蒙特卡罗方法在Koller和Friedman（2009）中更详细地描述。MCMC技术的最标准的通用保证仅适用于模型不将零概率分配给任何状态的情况。因此，将这些技术作为从基于能量的模型（EBM）p（x）αexp（-E（x））的采样呈现是最方便的，如在16.2.4。在EBM公式中，每个状态都保证具有非零概率。MCMC方法实际上更广泛地适用，并且可以与包含零概率状态的许多概率分布一起使用。然而，关于MCMC方法的行为的理论保证必须在不同种类的这种分布的情况下逐个证明。在深度学习的背景下，最常见的是依赖于自然地应用于所有基于能量的模型的最一般的理论保证。
为了理解为什么从基于能量的模型中抽取样本是困难的，考虑一个只有两个变量的EBM，定义一个分布p（a，b）。为了抽样a，我们必须从p（a | b）中抽取a，为了抽样b，我们必须从p（b | a）中抽取。它似乎是一个棘手的鸡和鸡蛋问题。有向模型避免了这种情况，因为它们的图是有向和无环的。要执行祖先采样，只需按拓扑顺序对每个变量进行采样，对每个变量的父节点进行调节，保证它们已经被采样（第16.3节）。祖先采样定义了获得样本的有效的单程方法。
在EBM中，我们可以通过使用马尔可夫链进行抽样来避免这种鸡和鸡蛋的问题。马尔可夫链的核心思想是具有以任意值开始的状态x。 随着时间的推移，我们重复地随机更新x。最终x变成（非常接近）来自p（x）的平稳样本。形式上，马尔科夫链由随机状态x和转变分布T（x0 | x）定义，转移分布T（x0 | x）指定如果在状态x开始随机更新将进入状态x0的概率。运行马尔科夫链意味着重复地将状态x更新为从T（x0 | x）采样的值x0。
为了获得对MCMC方法如何工作的一些理论的理解，重新定义问题是有用的。首先，我们将注意力限制在随机变量x具有可数许多状态的情况。在这种情况下，我们可以将状态表示为正整数x。不同的整数值x映射回原始问题中的不同状态x。
当我们考虑并行运行无限多个马尔可夫链时会发生什么。不同马尔可夫链的所有状态都来自某些分布q（t）（x），其中t表示已经过去的时间步长的数量。开始，q（0）是我们用于任意初始化每个马尔科夫链的x的一些分布。后来，q（t）受到迄今运行的所有马尔可夫链步长的影响。我们的目标是使q（t）（x）收敛到p（x）。
因为我们用正整数x重新定义了问题，所以我们可以使用向量v描述概率分布q，考虑当我们将单个马尔可夫链的状态x更新为新的状态x0时会发生什么。单状态落到状态x0的概率由下式给出，使用我们的整数参数化，我们可以使用矩阵A表示转换算子T的效果。我们定义A，使用这个定义，我们现在可以重写等式17.18。不使用q和T来描述单个状态是如何更新的，我们现在可以使用v和A来描述所有不同马尔科夫链上的整个分布如何在并行移动中运行，当我们执行更新时，重复应用马尔科夫链更新对应于乘以矩阵A. 换句话说，我们可以把过程看作矩阵A的指数：矩阵A具有特殊的结构，因为它的每列表示概率分布。这种矩阵被称为随机矩阵(stochastic matrices)。如果存在从任何状态x到某个功率t的任何其它状态x0的概率都为非零，则Perron-Frobenius定理（Perron，1907; Frobenius，1908）保证最大特征值是有理数并且等于1。随着时间的推移，我们可以看到所有的特征值都取幂：该过程使不等于1的所有特征值衰减到零。在一些附加的温和条件下，A被保证仅具有一个具有特征值1的特征向量。该过程因此收敛到静态分布，有时也称为平衡分布。在收敛时，并且该相同条件适用于每个后续步骤。这是一个特征向量方程。为了成为固定点，v必须是具有对应特征值1的特征向量。该条件保证一旦我们达到稳定分布，重复应用的过渡采样过程不改变所有各种马尔可夫链的状态分布（虽然转换算子确实改变每个单独的状态，当然）。
如果我们正确地选择了T，则平稳分布q将等于我们希望采样的分布p。 我们将在章节17.4快速描述如何选择T。
具有可数状态的马尔科夫链的大多数属性可以推广到连续变量。在这种情况下，一些作者将马可夫链称为哈里斯链，但我们使用术语马可夫链来描述这两个条件。一般来说，具有转换算子T的马尔科夫链在温和条件下会收敛到由等式描述的固定点，其在离散情况下只是重写等式17.23。当x是离散的时，期望对应于和，并且当x是连续的时，期望对应于积分。
不管状态是连续的还是离散的，所有马尔科夫链方法都包括重复地应用随机更新直到最终状态，开始从平衡分布产生样本。运行马尔科夫链，直到它达到其平衡分布（的过程）被称为“燃烧”马尔可夫链。在链达到平衡之后，可以从平衡分布中抽取无限多个样本的序列。它们是相同分布的，但是任何两个连续的样本将彼此高度相关。因此，有限的样本序列不能很好地代表平衡分布。减轻这个问题的一种方法是仅返回每n个连续样本，使得我们对平衡分布统计的估计不会因MCMC样本和接下来的几个样本之间的相关性而有偏差。因此使用马尔科夫链的开销较大，因为燃烧到平衡分布所需的时间和在达到平衡之后从一个样品转变到另一个合理去相关的样品所需的时间。如果需要真正独立的样本，可以并行运行多个马尔科夫链。这种方法使用额外的并行计算来消除延迟。仅使用单个马尔科夫链来生成所有样本的策略和对于每个期望样本使用一个马尔科夫链的策略是两个极端;深度学习实践者通常使用与小批量中的示例数量相似的多个链，然后从这个固定的马尔科夫链中抽样所需的多个样本。常用的马可夫链数为100。
另一个困难是，我们不知道马尔可夫链在达到其平衡分布之前必须运行多少步。该时间长度称为混合时间（mixing time）。测试马尔可夫链是否达到平衡也是非常困难的。我们没有一个准确的理论来指导我们回答这个问题。理论告诉我们，链条会收敛，但不会告诉更多。如果我们从作用于概率v的向量的矩阵A的角度分析马尔可夫链，则当At已经有效地丢失了来自A的除了唯一特征值1之外的所有特征值时链会混合。这意味着第二大特征值的大小将确定混合时间。然而，在实践中，我们实际上不能用矩阵表示我们的马尔科夫链。我们的概率模型可以访问的状态的数量在变量的数量是指数地大，因此表示v，A或A的特征值是不可行的。由于这些和其他障碍，我们通常不知道马尔科夫链已混合。 相反，我们只是运行马尔可夫链一段时间，我们粗略估计是足够的，并使用启发式方法来确定链是否混合。这些启发式方法包括手动检查样本或测量连续样本之间的相关性。###17.4	吉布斯采样（Gibbs Sampling）目前为止我们已经讨论了如何通过重复地更新x ← x ∼ T (x | x)来从一个分布q(x)中采样。但是，我们并没有描述如何保证q(x)是一个有用的分布。本书中讨论了两种基本的方法。第一种是从给定的习得模型pmodel中导出T，下面将以从EBM中采样为例来描述。第二个是直接参数化T并且学习它，使得其静态分布隐含地定义了感兴趣的pmodel。第二种方法的例子将在章节20.12和章节20.13中讨论。
在深度学习的上下文中，我们通常使用马尔科夫链从基于能量的模型定义的分布pmodel（x）中抽取样本。在这种情况下，我们希望马尔科夫链的q（x）是pmodel（x）。为了获得期望的q（x），我们必须选择适当的T（x’| x）。
一个概念上简单和有效的构建从pmodel（x）采样的马尔可夫链的方法是使用吉布斯采样（Gibbs sampling），其中在定义基于能量的模型的结构的无向图G中，通过选择一个变量xi并从其邻居对pmodel进行采样来完成从T（x0 | x）的采样。也可以同时对几个变量进行采样，只要它们在给定它们所有邻居的情况下是条件独立的。如章节16.7.1中所示的RBM的示例。RBM的所有隐藏单元可以被同时采样，因为它们在给定所有可见单元的情况下彼此条件独立。同样，所有可见单元可以被同时采样，因为它们在给定所有隐藏单元的情况下彼此条件独立。以这种方式同时更新许多变量的吉布斯采样方法称为块吉布斯采样（block Gibbs sampling）。设计马可夫链从pmodel中采样的其他方法是可能的。例如，Metropolis-Hastings算法广泛应用于其他学科中。在无向建模的深度学习方法的背景下，很少使用除了吉布斯抽样之外的任何方法。改进的抽样技术可能是一个研究的前沿。
###17.5	 分离模型间融合的挑战（The Challenge of Mixing between Separated Modes）MCMC方法的主要困难是它们具有混合较差的倾向。理想情况下，来自被设计为从p（x）采样的马尔可夫链的连续样本将彼此完全独立，并且按照它们的概率比例将访问x空间中的许多不同区域。相反，特别是在高维的情况下，MCMC产生的样本将变得非常相关。我们称这样的行为是慢混合或者失败混合。具有慢混合的MCMC方法可以被视为对于能量函数无意地执行类似于噪声梯度下降的事物，或者相对于链的状态（随机变量被采样），等效地对噪声爬坡对概率的执行。该链趋于采取小的步长（在马尔可夫链的状态的空间中）从配置x（t-1）到配置x（t），其中能量E（x（t））通常较低，近似等于能量E（x（t-1）），优选产生较低能量配置的移动。当从相当不可能的配置（比来自p（x）的典型的能量更高的能量）开始时，链趋向于逐渐减少状态的能量，并且仅仅偶尔移动到另一模式。一旦链已经找到低能量的区域（例如，如果变量是图像中的像素，则低能量的区域可以是同一对象的图像连接的多边形），我们称之为模式，链将倾向于围绕那种模式走（跟随一种随机游走）。偶尔它会退出该模式，一般是返回它或者（如果找到一个逃生路线）向另一种模式移动。问题是对于有很多有趣的分布，成功的逃避路线很少，所以马尔可夫链将比原本更长地继续抽样相同的模式。
当我们考虑吉布斯采样算法（章节17.4）时，这是非常清楚的。在此上下文中，考虑在给定数量的步骤内从一个模式转移到附近模式的概率。决定这些概率的是这些模式之间的“能量势垒”的形状。由高能量势垒（低概率区域）分开的两个模式之间的转变在指数上不太可能（就能量势垒的高度而言）。这如图17.1中所示。当存在由概率较低的区域分隔的具有高概率的多个模式时，特别是当每个Gibbs采样步骤必须仅更新其值主要由其他变量确定的变量的小子集时，问题就会出现。
作为一个简单的例子，考虑两个变量a和b上的基于能量的模型，它们都是具有符号的二进制数，取值-1和1。如果对于一些大的正数w，E（a，b）= -wab ，则该模型表达了a和b具有相同符号的强烈信念。 考虑使用具有a = 1的Gibbs采样步骤来更新b。通过P（b = 1 | a = 1）=σ（w）给出b上的条件分布。如果w大，则S形饱和，并且也将b分配为1的概率接近于1。同样，如果a = -1，则将b分配为-1的概率接近于1。根据Pmodel（a，b），两个变量的两个符号同样可能。 根据Pmodel（a | b），两个变量应该具有相同的符号。 这意味着吉布斯抽样只能极少地翻转这些变量的符号。
在更实际的场景中，挑战更大，因为我们不仅关心在两种模式之间进行转换，而且更一般地在真实模型可能包含的所有许多模式之间转换。如果由于模式之间混合的困难而难以进行若干这样的转换，则获得覆盖大多数模式的可靠的样本集合将变得非常昂贵，并且链收敛到其稳定分布是非常慢的。
有时这个问题可以通过查找高度依赖单位的组，并在块中同时更新所有单位来解决。不幸的是，当依赖性复杂时，从组中抽取样本在计算上是难以处理的。毕竟，最初引入马尔科夫链来解决的问题是从大量变量中抽样的问题。
在包含联合分布pmodel（x，h）隐变量的模型的上下文中，我们经常通过在从pmodel（x | h）的采样和从pmodel（h | x）的采样之间交替来采样x。从快速混合的角度来看，我们希望pmodel（h | x）具有非常高的熵。 然而，从学习h的有用表征的角度来看，我们希望h对关于x的足够的信息进行编码以重建它，这意味着h和x应当具有非常高的相互信息。这两个目标是相互矛盾的。我们经常学习生成模型，非常精确地将x编码为h，但不能很好地混合。这种情况经常出现在玻尔兹曼机器上 - 玻尔兹曼机器学习的分布越尖锐，对模型分布的马尔可夫链采样越难以混合。这个问题如图17.2中所示。
当感兴趣的分布对于每个类具有单独的流形结构时，所有这些都能够使得MCMC方法更不可用：分布集中在许多种模式周围，并且这些模式被大量高能量的区域分离。这种类型的分布是我们在许多分类问题中期望的，并且将使MCMC方法非常缓慢地收敛，因为模式之间的不良混合。
####17.5.1	退火来混合不同模式（Tempering to Mix between Modes）当一个分布具有由概率较低的区域包围的概率较高的尖峰时，难以在分布的不同模式之间混合。使得混合更快的几种技术是基于构造目标分布的替代版本，其中峰值不那么高而周围的谷值也不低。基于能量的模型提供了一种特别简单的方法。到目前为止，我们已经描述了基于能量的模型来定义的概率分布基于能量的模型可以用额外的参数β来扩充，该参数β控制该分布的尖峰：β参数通常被描述为温度的倒数，反映了统计物理学中基于能量的模型的起源。当温度下降到零并且β上升到无穷大时，基于能量的模型变得确定。当温度上升到无穷大并且β下降到零时，分布（对于离散x）变得均匀。
通常，训练模型是以在β= 1时进行评估。然而，我们可以利用其他温度，特别是β<1的温度。退火是通过在β<1时抽样来快速混合模型p1的一般策略。
基于退火过渡的马尔科夫链（Neal，1994）暂时从较高温度分布中采样以便混合到不同模式，然后从单元温度分布中恢复采样。这些技术已经应用于诸如RBM的模型（Salakhutdinov，2010）。另一种方法是使用并行退火（Iba，2001），其中马尔可夫链在不同温度下模拟并行的许多不同状态。最高温度状态缓慢混合，而最低温度状态，如温度1，从模型中提供准确的样本。转换算子包括两个不同温度水平之间的随机交换状态，使得来自高温槽的概率足够高的样本可以跳入较低温槽中。这种方法也已经应用于RBM（Desjardins等人，2010; Cho等人，2010）。虽然调温是一种有前途的方法，但在这一点上，它不允许研究人员在解决从复杂EBM采样的挑战方面取得巨大的进步。一个可能的原因是临界温度的存在，在该临界温度附近温度转变必须非常缓慢（随着温度逐渐降低），以使退火有效。
####17.5.2	深度有可能帮助混合（Depth May Help Mixing）当从隐变量模型p（h，x）抽样时，我们已经看到如果p（h | x）对x的编码太好，则从p（x | h）的采样不会剧烈改变x，混合也较差。解决这个问题的一种方法是使h成为深度表示，其将x编码为h，使得h空间中的马尔可夫链可以更容易地混合。许多表征学习算法（例如自动编码器和RBM）倾向于产生在h上的边缘分布，其比x上的原始数据分布更均匀和更单调。可以认为，这是由于试图在使用所有可用的表示空间时最小化重建误差，因为当不同的训练样本在h空间中容易彼此区分时，将更好地实现训练样本上的最小重建误差，以及更好地实现分离。Bengio等人（2013a）观察到，正则化自动编码器或RBM的更深层叠在顶层h空间中产生边缘分布，其更加扩展和更均匀，在对应于不同模式的区域之间具有较小的间隙（在实验中是指类别）。在较高维度的空间中训练RBM可以使Gibbs采样在模式之间更快地混合。然而，它仍然不清楚如何利用这种观察，来帮助更好地训练和从深度生成模型中抽样。
尽管混合时有困难，蒙特卡罗技术仍然是有用的，而且通常是最好的工具。事实上，它们是用于面对无向模型中难处理的分区函数的主要工具，将在接下来讨论。